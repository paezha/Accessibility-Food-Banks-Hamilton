---
title: "00-Data-Processing-for-Food-Banks-Accessibility"
---

## Introduction

In this notebook we create some examples of processing the data for the analysis of accessibility to food banks in Hamilton. Particularly, we're interested in spatial interpolation of the population for small areas.

## Preliminaries

Clear environment:
```{r}
rm(list = ls())
```

Load packages used in the notebook:
```{r message = FALSE}
library(cancensus)
library(disk.frame)
#library(pycno)
library(readr)
library(r5r) # the r5r package requires Java Development Kit version 11, which can be downloaded from https://www.oracle.com/java/technologies/javase-jdk11-downloads.html
library(sf)
library(smoothr)
library(tidyverse)
library(tmap)
library(tmaptools)
```

Define some parameters for `disk.frame` and `r5r`:
```{r}
setup_disk.frame()
options(scipen = 999)
options(java.parameters = "-Xmx6G")
options(future.globals.maxSize = Inf)
```

Data used in this notebook was retrieved from two sources: Open Hamilton and the 2016 Canadian Census. Open Hamilton is an online repository of data from the City of Hamilton. The provenance of the datasets is below.

## Provenance of data: 

### Hamilton CMA boundaries

Statistics Canada. Load:
```{r}
load("input-data-files/hamilton_cma.RData")
#load("input-data-files/hamilton_da_2016.RData")
```

### Hamilton Ward boundaries

Open Data Hamilton. Read:
```{r}
wards <- st_read("input-data-files/Ward_Boundaries.shp")
```

Add label for type of ward (the urban/suburban/rural classification is by the planning teams; see https://www.hamilton.ca/develop-property/planning-applications/development-applications-mapping)
```{r}
wards$Type <- c("Urban",
                "Urban",
                "Urban",
                "Urban",
                "Urban",
                "Suburban",
                "Suburban",
                "Suburban",
                "Suburban",
                "Suburban",
                "Suburban",
                "Suburban",
                "Suburban",
                "Suburban",
                "Suburban")
```

Merge boundaries by type:
```{r}
wards <- wards %>% 
  group_by(Type) %>%
  summarize()
```

```{r}
ggplot(wards) + 
  geom_sf(aes(fill = Type))
```

Read rural boundary:
```{r}
rural <- st_read("input-data-files/Rural_Boundary.shp")
rural <- rural %>%
  transmute(Type = "Rural")
```

Plot rural boundary:
```{r}
ggplot(rural) +
  geom_sf()
```

Obtain difference between urban and suburban regions and rural boundary:
```{r}
st_difference(wards, rural) %>%
  ggplot() +
  geom_sf(aes(fill = Type))
```

Notice the detritus after the difference. Drop crumbs to obtain a cleaner version of the boundaries:
```{r}
sub_urban <- st_difference(wards, rural) %>%
  transmute(Type) %>%
  smoothr::drop_crumbs(threshold = 5000)

ggplot(sub_urban) +
  geom_sf(aes(fill = Type))
```

Bind the boundaries with all three urban types:
```{r}
urban_types <- rbind(sub_urban,
                     rural)

ggplot(urban_types) +
  geom_sf(aes(fill = Type))
```

### Location of food banks

Read file with locations:
```{r}
foodbank_locations <- read_csv("input-data-files/foodbanks-hamilton.csv",
                               col_types = cols(ID = col_double(),
                                    NAME = col_character(),
                                    TYPE = col_character(),
                                    ADDRESS = col_character(),
                                    COVIDClose = col_double(),
                                    latitude = col_double(),
                                    longitude = col_double(),
                                    name = col_character(),
                                    desc = col_character(),
                                    source = col_character(),
                                    precision = col_character()
                               ))
```

COVIDClose is an indicator variable for whether this bank closed during the pandemic. Convert to factor:
```{r}
foodbank_locations <- foodbank_locations %>%
  mutate(COVIDClose = replace_na(COVIDClose, 0),
         COVIDClose = factor(COVIDClose,
                             levels = c(0, 1),
                             labels = c("No", "Yes")))
```


Convert to simple features:
```{r}
foodbank_locations <- foodbank_locations %>%
  st_as_sf(coords = c("longitude", "latitude"), 
           crs = 4326) %>%
  st_transform(crs = 26917)
```

Map location of foodbanks:
```{r}
ggplot() +
  geom_sf(data = hamilton_cma) +
  geom_sf(data = foodbank_locations,
          aes(shape = COVIDClose,
              color = COVIDClose))
```

### `dwelling_network_points_2016.RData` 

This is based on parcel-level data, approximated to the nearest point on the road network. For processing details, see:

https://github.com/paezha/Accessibility-to-Schools-Hamilton-Equity

```{r}
load("input-data-files/dwelling_network_points_2016.RData")
```

### Census data

We can get an API key to use `cancensus` from [CensusMapper](https://censusmapper.ca/). Once you have an API key, it can be stored locally this way:
```{r eval=FALSE}
set_api_key("your-key", install = TRUE)
```

Once you have your API you can use `cancensus` like in this example.

Use `cancensus` to check and download census data. Check the regions:
```{r}
list_census_regions('CA16') %>% 
  dplyr::filter(level == "CMA", name %in% c("Hamilton"))
```

We need PR_UID 35.

List census data sets:
```{r}
list_census_datasets()
```

We need CA16.

Search variables:
```{r}
find_census_vectors("income", 
                    dataset = "CA16", 
                    type = "total", 
                    query_type = "keyword", 
                    interactive = FALSE)
```

We need v_CA16_2406 to v_CA16_2425: these are the number of households at certain levels of total income. Retrieve data:
```{r}
data_da_2016 <- get_census(dataset='CA16', 
                          regions=list(CMA=c("35537")),
                          vectors=c("v_CA16_2406",
                                    "v_CA16_2407",
                                    "v_CA16_2408",
                                    "v_CA16_2409",
                                    "v_CA16_2410",
                                    "v_CA16_2411",
                                    "v_CA16_2412",
                                    "v_CA16_2413",
                                    "v_CA16_2414",
                                    "v_CA16_2415",
                                    "v_CA16_2416",
                                    "v_CA16_2417",
                                    "v_CA16_2418",
                                    "v_CA16_2419",
                                    "v_CA16_2420",
                                    "v_CA16_2421",
                                    "v_CA16_2422",
                                    "v_CA16_2423",
                                    "v_CA16_2424",
                                    "v_CA16_2425",
                                    "v_CA16_2426"),
                          level='DA', 
                          use_cache = FALSE,
                          geo_format = "sf")
```

Plot population:
```{r}
tmap_mode(mode = "view")

data_da_2016 %>%
  mutate(income_less20k = (`v_CA16_2406: Under $5,000` + 
                  `v_CA16_2407: $5,000 to $9,999` + 
                  `v_CA16_2408: $10,000 to $14,999` +
                  `v_CA16_2409: $15,000 to $19,999`)) %>%
  tm_shape() +
  tm_polygons("income_less20k",
              alpha = 0.8)
```

### Transportation Tomorrow Survey

I downloaded a cross-tabulation of travel mode by age by traffic analysis zone. Read the shape file with the traffic analysis zone boundaries:
```{r}
tts_taz <- st_read("input-data-files/tts2016_2006zn_2018_region.shp")
```

Filter Hamilton (region 6):
```{r}
tts_taz <- tts_taz %>%
  dplyr::filter(region == 6)

ggplot() +
  geom_sf(data = tts_taz)
```

Read transportation data:
```{r}
travel_modes <- read_csv("input-data-files/ttsCross70628.csv",
                         col_types = cols(gta06_hhld = col_double(),
                                          income = col_double(),
                                          total = col_double(),
                                          Mode = col_character()
                                          ))
```


Code | Income
-- | --
1	| \$0 to $14999
2	| \$15000 to $39999
3	| \$40000 to $59999
4	| \$60000 to $99999
5	| \$100000 to $124999
6	| \$125000 and above
7	Decline / don't know

Filter modes:
```{r}
travel_modes <- travel_modes %>%
  dplyr::filter(Mode == "Auto driver" |
                  Mode == "Transit (Excluding GO rail)" |
                  Mode == "Walk")
```

THE NEXT NEEDS TO BE CHANGED TO DO THE ANALYSIS BY INCOME GROUP, NOT BY AGE GROUP

### Ages 55-69

Filter age:
```{r}
travel_modes_1 <- travel_modes %>%
  dplyr::filter(age >= 55 & age < 70)
```

Summarize trips by mode by traffic analysis zone:
```{r}
travel_modes_1 <- travel_modes_1 %>%
  group_by(gta06_hhld, Mode) %>%
  summarize(trips = sum(total),
            .groups = "drop")
```

Pivot wider and rename columns:
```{r}
travel_modes_1 <- travel_modes_1 %>%
  rename(TAZUID = gta06_hhld) %>%
  pivot_wider(names_from = Mode,
              values_from = trips,
              values_fill = 0) %>%
  rename(Driver = `Auto driver`, 
         Transit = `Transit (Excluding GO rail)`)
```

Join geometry:
```{r}
travel_modes_1 <- tts_taz %>%
  dplyr::transmute(TAZUID = gta06, geometry) %>%
  left_join(travel_modes_1 %>%
              st_drop_geometry(),
            by = "TAZUID") %>%
  st_as_sf()
```

Plot trips as driver:
```{r}
ggplot() +
  geom_sf(data = travel_modes_1,
          aes(fill = Driver))
```

Plot trips transit:
```{r}
ggplot() +
  geom_sf(data = travel_modes_1,
          aes(fill = Transit))
```

Plot walking trips:
```{r}
ggplot() +
  geom_sf(data = travel_modes_1,
          aes(fill = Walk))
```

### Ages 70+

Filter age:
```{r}
travel_modes_2 <- travel_modes %>%
  dplyr::filter(age >= 70)
```

Summarize trips by mode by traffic analysis zone:
```{r}
travel_modes_2 <- travel_modes_2 %>%
  group_by(gta06_hhld, Mode) %>%
  summarize(trips = sum(total),
            .groups = "drop")
```

Pivot wider and rename columns:
```{r}
travel_modes_2 <- travel_modes_2 %>%
  rename(TAZUID = gta06_hhld) %>%
  pivot_wider(names_from = Mode,
              values_from = trips,
              values_fill = 0) %>%
  rename(Driver = `Auto driver`, 
         Transit = `Transit (Excluding GO rail)`)
```

Join geometry:
```{r}
travel_modes_2 <- tts_taz %>%
  dplyr::transmute(TAZUID = gta06, geometry) %>%
  left_join(travel_modes_2 %>%
              st_drop_geometry(),
            by = "TAZUID") %>%
  st_as_sf()
```

Plot trips as driver:
```{r}
ggplot() +
  geom_sf(data = travel_modes_2,
          aes(fill = Driver))
```

Plot trips transit:
```{r}
ggplot() +
  geom_sf(data = travel_modes_2,
          aes(fill = Transit))
```

Plot walking trips:
```{r}
ggplot() +
  geom_sf(data = travel_modes_2,
          aes(fill = Walk))
```

Rename tables:
```{r}
modes_55to69 <- travel_modes_1
modes_70plus <- travel_modes_2
```

## Join TAZ identifiers to parcel table

This will be a spatial join:
```{r}
nearest_network_point_2016 <- nearest_network_point_2016 %>%
  st_join(tts_taz %>%
            transmute(TAZUID = gta06))
```


## Routing for entire system

I used [BBBike](https://download.bbbike.org/osm/bbbike/) to extract OSM data for Hamilton. The name of the file is `planet_-80.279,43.048_-79.318,43.459.osm.pbf`. Copy to folder `r5_graph`.

Set Up R5 Routing. First define the path to where the graph is located:
```{r set up r5 path, include=FALSE}
r5_path <- file.path("./r5_graph")
```

Download and import GTFS (Hamilton transit data)
```{r eval=FALSE}
download.file(url = "https://transitfeeds.com/p/hamilton-street-railway/31/latest/download", destfile = file.path(r5_path, "HSR_transit.zip"), mode = "wb")
```

Download and import GTFS (Hamilton transit data)
```{r eval=FALSE}
download.file(url = "https://transitfeeds.com/p/burlington-transit/294/latest/download", destfile = file.path(r5_path, "Burlington_transit.zip"), mode = "wb")
```

Build the graph:
```{r build-graph, include = FALSE}
r5_hamilton_cma <- setup_r5(data_path = r5_path, verbose = FALSE)
```

Prepare Input Data for `r5r`. The origins are the coordinates of the parcels and the destinations the coordinates of the pharmacies:
```{r prepare-inputs}
# save origins in format expected by R5R (id, lon, lat)
origins_i <- data.frame(ID = nearest_network_point_2016$ID, 
              nearest_network_point_2016 %>%
                st_transform(crs = 4326) %>%
                st_coordinates()) %>%
    rename(lon = X, lat = Y, id = ID) %>%
    dplyr::select(id, lon, lat)

# now vaccination sites
destinations_j <- data.frame(ID = pharmacy_locations$ID, 
              pharmacy_locations %>%
                st_transform(crs = 4326) %>%
                st_coordinates()) %>%
    rename(lon = X, lat = Y, id = ID) %>%
    dplyr::select(id, lon, lat)
```

Calculate OD Matrix for car:
```{r calculate car od matrix}
# set up batching according to how many origin rows to process at one time
chunksize = 2000 # larger chunks for walking will give enough origins in each chunk to allow multiprocessing to spin up with R5R
num_chunks = ceiling(nrow(origins_i)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(origins_i,
                          outdir = "./df/origins_i",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){ 
  origins_i_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5_hamilton_cma,
                          origins = origins_i_chunk,
                          destinations = destinations_j,
                          mode = c("CAR"),
                          mode_egress = c("WALK"),
                          departure_datetime = as.POSIXct(strptime("2021-04-05 08:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
                          max_walk_dist = 10000, # metres
                          max_trip_duration = 180)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "./df/output_ttm_car",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
ttm_car_time <- end.time - start.time
ttm_car_time
```

Calculate OD Matrix for transit:
```{r calculate transit od matrix}
# set up batching according to how many origin rows to process at one time
chunksize = 2000 # larger chunks for walking will give enough origins in each chunk to allow multiprocessing to spin up with R5R
num_chunks = ceiling(nrow(origins_i)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(origins_i,
                          outdir = "./df/origins_i",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){
  origins_i_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5_hamilton_cma,
                          origins = origins_i_chunk,
                          destinations = destinations_j,
                          mode = c("TRANSIT"),
                          mode_egress = c("WALK"),
                          departure_datetime = as.POSIXct(strptime("2021-04-05 08:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
                          max_walk_dist = 10000, # metres
                          max_trip_duration = 180)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "./df/output_ttm_transit",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
ttm_transit_time <- end.time - start.time
ttm_transit_time
```

Calculate OD Matrix for walking:
```{r calculate walk od matrix}
# set up batching according to how many origin rows to process at one time
chunksize = 2000 # larger chunks for walking will give enough origins in each chunk to allow multiprocessing to spin up with R5R
num_chunks = ceiling(nrow(origins_i)/chunksize)

# create origin-destination pairs
origins_chunks <- as.disk.frame(origins_i,
                          outdir = "./df/origins_i",
                          nchunks = num_chunks,
                          overwrite = TRUE)

start.time <- Sys.time()
pb <- txtProgressBar(0, num_chunks, style = 3)

for (i in 1:num_chunks){ 
  origins_i_chunk <- get_chunk(origins_chunks, i)
  ttm_chunk <- travel_time_matrix(r5_hamilton_cma,
                          origins = origins_i_chunk,
                          destinations = destinations_j,
                          mode = c("WALK"),
                          departure_datetime = as.POSIXct(strptime("2021-04-05 08:00:00", "%Y-%m-%d %H:%M:%S", tz = "EST5EDT")),
                          max_walk_dist = 10000, # metres
                          max_trip_duration = 180)
  
  # export output as disk.frame
  ifelse(i == 1, output_df <- as.disk.frame(ttm_chunk,
                                            nchunks = 1,
                                            outdir = "./df/output_ttm_walk",
                                            compress = 50,
                                            overwrite = TRUE),
         add_chunk(output_df, ttm_chunk, chunk_id = i))
  setTxtProgressBar(pb, i)
}
end.time <- Sys.time()
ttm_walk_time <- end.time - start.time
ttm_walk_time
```

## Extract travel time matrix

```{r load od matrix for transit, include=FALSE}
# connect to the walking travel time matrix disk frame
ttm_transit.disk.frame <- disk.frame("./df/output_ttm_transit")
#opportunities_j <- as.data.frame(nyc_cb_point) %>% select(GEOID10, total_emp) %>% rename(toId = GEOID10, o_j = total_emp)
```

Convert disk.frame to data frame:
```{r}
ttm_transit <- as.data.frame(ttm_transit.disk.frame) %>%
  transmute(UID = as.numeric(fromId), OBJECTID = as.numeric(toId), travel_time)
```

```{r load od matrix for walk, include=FALSE}
# connect to the walking travel time matrix disk frame
ttm_walk.disk.frame <- disk.frame("./df/output_ttm_walk")
#opportunities_j <- as.data.frame(nyc_cb_point) %>% select(GEOID10, total_emp) %>% rename(toId = GEOID10, o_j = total_emp)
```

Convert disk.frame to data frame:
```{r}
ttm_walk <- as.data.frame(ttm_walk.disk.frame) %>%
  transmute(UID = as.numeric(fromId), OBJECTID = as.numeric(toId), travel_time)
```

```{r load od matrix for car, include=FALSE}
# connect to the walking travel time matrix disk frame
ttm_car.disk.frame <- disk.frame("./df/output_ttm_car")
#opportunities_j <- as.data.frame(nyc_cb_point) %>% select(GEOID10, total_emp) %>% rename(toId = GEOID10, o_j = total_emp)
```

Convert disk.frame to data frame:
```{r}
ttm_car <- as.data.frame(ttm_car.disk.frame) %>%
  transmute(UID = as.numeric(fromId), OBJECTID = as.numeric(toId), travel_time)
```

## Save data to disk

Clean `nearest_network_point_2016`:
```{r}
dwelling_network_points_2016 <- nearest_network_point_2016 %>%
  mutate(Dwellings = SINGLE_FAM + SEMI_DET + ROW_THOUSE + APARTMENT) %>%
  dplyr::select(-c(ROLL_NUM, LUC1, LUC1_DESC, SINGLE_FAM, SEMI_DET, ROW_THOUSE, APARTMENT))
```

Save data files:
```{r}
save(data_da_2016, file = "output-data-files/data_da_2016.RData", compress = "xz")
save(dwelling_network_points_2016, file = "output-data-files/dwelling_network_points_2016.RData", compress = "xz")
save(hamilton_cma, file = "output-data-files/hamilton_cma.RData", compress = "xz")
save(modes_55to69, file = "output-data-files/modes_55to69.RData", compress = "xz")
save(modes_70plus, file = "output-data-files/modes_70plus.RData", compress = "xz")
save(pharmacy_locations, file = "output-data-files/pharmacy_locations.RData", compress = "xz")
save(ttm_car, file = "output-data-files/ttm_car.RData", compress = "xz")
save(ttm_transit, file = "output-data-files/ttm_transit.RData", compress = "xz")
save(ttm_walk, file = "output-data-files/ttm_walk.RData", compress = "xz")
save(urban_types, file = "output-data-files/urban_types.RData", compress = "xz")
```

Copy files to folder `data` of the package.
